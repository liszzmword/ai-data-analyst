"""
í†µí•© ì§ˆì˜ ì²˜ë¦¬ê¸° - ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì§€ì›
ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´: ë°ì´í„° ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± â†’ Gemini ë¶„ì„ + ì˜ê²¬
"""
import google.generativeai as genai
import pandas as pd
from typing import Dict, Any, List
from dataclasses import dataclass

from config import GOOGLE_API_KEY
from router import QueryRouter
from calc_engine import CalcEngine
from lookup_engine import LookupEngine
from data_loader import DataLoader


# Gemini API ì„¤ì •
genai.configure(api_key=GOOGLE_API_KEY)


@dataclass
class UnifiedResponse:
    """í†µí•© ì‘ë‹µ"""
    mode: str
    query: str
    data_summary: str  # ë°ì´í„° ìš”ì•½
    gemini_analysis: str  # Gemini ë¶„ì„ + ì˜ê²¬
    raw_data: Any  # ì›ë³¸ ê³„ì‚°/ê²€ìƒ‰ ê²°ê³¼
    routing_info: str


class UnifiedProcessor:
    """ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì§€ì› ì²˜ë¦¬ê¸°"""

    def __init__(self, data_loader: DataLoader):
        self.data_loader = data_loader
        self.router = QueryRouter()
        self.calc_engine = CalcEngine(data_loader)
        self.lookup_engine = LookupEngine(data_loader)
        self.llm = genai.GenerativeModel('gemini-2.5-flash')

        print("âœ“ í†µí•© ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def process(self, query: str, dataset_filter: str = "ì „ì²´") -> UnifiedResponse:
        """
        ì§ˆë¬¸ ì²˜ë¦¬: ë°ì´í„° ìˆ˜ì§‘ â†’ Gemini ë¶„ì„

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            dataset_filter: ë°ì´í„°ì…‹ í•„í„°

        Returns:
            UnifiedResponse
        """
        print(f"\n{'='*60}")
        print(f"ğŸ” ì§ˆë¬¸: {query}")
        print(f"{'='*60}")

        # 1. ë¼ìš°íŒ…
        routing = self.router.route(query)
        print(f"ğŸ“ ëª¨ë“œ: {routing.mode} ({routing.confidence:.0%})")
        print(f"   ì´ìœ : {routing.reasoning}")

        # 2. ëª¨ë“œë³„ ë°ì´í„° ìˆ˜ì§‘
        if routing.mode == "CALC":
            data_summary, raw_data = self._collect_calc_data(query, dataset_filter)
        elif routing.mode == "LOOKUP":
            data_summary, raw_data = self._collect_lookup_data(query, dataset_filter)
        else:  # RAG
            data_summary, raw_data = self._collect_rag_data(query)

        # 3. Gemini ë¶„ì„ + ì˜ê²¬
        gemini_analysis = self._generate_analysis(query, data_summary, routing.mode)

        return UnifiedResponse(
            mode=routing.mode,
            query=query,
            data_summary=data_summary,
            gemini_analysis=gemini_analysis,
            raw_data=raw_data,
            routing_info=routing.reasoning
        )

    def _collect_calc_data(self, query: str, dataset_filter: str) -> tuple[str, Any]:
        """CALC ëª¨ë“œ: pandas ê³„ì‚° ìˆ˜í–‰"""
        print("ğŸ“Š pandas ê³„ì‚° ì¤‘...")

        result = self.calc_engine.calculate(query, dataset_filter)

        # ë°ì´í„° ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
        summary_parts = []

        if result.filter_conditions:
            summary_parts.append(f"**ì ìš© ì¡°ê±´**: {', '.join(result.filter_conditions)}")

        if result.result_df is not None and len(result.result_df) > 0:
            summary_parts.append(f"\n**ê³„ì‚° ê²°ê³¼** ({len(result.result_df)}ê°œ í•­ëª©):\n")
            summary_parts.append(result.result_df.head(10).to_string())

            # ìƒ˜í”Œ ì›ë³¸ ë°ì´í„°
            if result.sample_rows:
                summary_parts.append("\n\n**ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ**:")
                for i, row in enumerate(result.sample_rows[:3], 1):
                    summary_parts.append(f"\n{i}. {row}")

        data_summary = "\n".join(summary_parts)

        return data_summary, result

    def _collect_lookup_data(self, query: str, dataset_filter: str) -> tuple[str, Any]:
        """LOOKUP ëª¨ë“œ: ë ˆì½”ë“œ ê²€ìƒ‰"""
        print("ğŸ” ë ˆì½”ë“œ ê²€ìƒ‰ ì¤‘...")

        result = self.lookup_engine.lookup(query, dataset_filter)

        # ë°ì´í„° ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
        summary_parts = []

        if result.search_conditions:
            summary_parts.append(f"**ê²€ìƒ‰ ì¡°ê±´**: {result.search_conditions}")

        if result.found_records:
            summary_parts.append(f"\n**ê²€ìƒ‰ ê²°ê³¼**: {len(result.found_records)}ê°œ ë ˆì½”ë“œ\n")

            for i, record in enumerate(result.found_records[:5], 1):
                summary_parts.append(f"\n[ë ˆì½”ë“œ {i}]")
                for key, value in list(record.items())[:10]:
                    if key not in ['dataset', 'row_id']:
                        summary_parts.append(f"  {key}: {value}")
        else:
            summary_parts.append("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

        data_summary = "\n".join(summary_parts)

        return data_summary, result

    def _collect_rag_data(self, query: str) -> tuple[str, Any]:
        """RAG ëª¨ë“œ: ì½”ë“œë¶ ì •ë³´"""
        print("ğŸ“š ì½”ë“œë¶ ê²€ìƒ‰ ì¤‘...")

        # ì½”ë“œë¶ì—ì„œ ì§ì ‘ ê²€ìƒ‰
        codebook_df = self.data_loader.codebook_loader.codebook_df

        # ê´€ë ¨ í•­ëª© ì°¾ê¸°
        relevant_items = []
        for idx, row in codebook_df.iterrows():
            row_text = f"{row.get('ë²ˆí˜¸', '')} {row.get('í•­ëª©', '')} {row.get('í•­ëª©ì„¤ëª…', '')}"
            if any(keyword in row_text for keyword in [query, query.replace(' ', '')]):
                relevant_items.append(row)

        if not relevant_items:
            # í‚¤ì›Œë“œë¡œ ì¬ê²€ìƒ‰
            for idx, row in codebook_df.iterrows():
                row_text = str(row).lower()
                if any(keyword.lower() in row_text for keyword in query.split()):
                    relevant_items.append(row)

        # ë°ì´í„° ìš”ì•½
        summary_parts = []
        summary_parts.append("**ì½”ë“œë¶ ì •ë³´**:\n")

        for i, item in enumerate(relevant_items[:5], 1):
            summary_parts.append(f"{i}. ë²ˆí˜¸: {item.get('ë²ˆí˜¸', 'N/A')}")
            summary_parts.append(f"   í•­ëª©: {item.get('í•­ëª©', 'N/A')}")
            summary_parts.append(f"   ì„¤ëª…: {item.get('í•­ëª©ì„¤ëª…', 'N/A')}")
            summary_parts.append(f"   íŒŒì¼: {item.get('íŒŒì¼ êµ¬ë¶„', 'N/A')}\n")

        if not relevant_items:
            summary_parts.append("ê´€ë ¨ ì½”ë“œë¶ í•­ëª© ì—†ìŒ")

        data_summary = "\n".join(summary_parts)

        return data_summary, relevant_items

    def _generate_analysis(self, query: str, data_summary: str, mode: str) -> str:
        """Geminië¡œ ë°ì´í„° ë¶„ì„ + ì˜ì‚¬ê²°ì • ì§€ì›"""
        print("ğŸ¤– Gemini ë¶„ì„ ì¤‘...")

        prompt = f"""ë‹¹ì‹ ì€ **ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€**ì…ë‹ˆë‹¤.

ì‚¬ìš©ìëŠ” ì˜ì‚¬ê²°ì •ì„ ìœ„í•´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì—­í• : ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ê³ , êµ¬ì²´ì ì¸ ì˜ê²¬ì„ ì œì‹œí•˜ì„¸ìš”.

**ì‚¬ìš©ì ì§ˆë¬¸**: {query}

**ìˆ˜ì§‘ëœ ë°ì´í„°**:
{data_summary}

**ë‹µë³€ ì‘ì„± ê°€ì´ë“œ**:
1. **ë°ì´í„° ìš”ì•½**: í•µì‹¬ ìˆ˜ì¹˜/íŒ¨í„´ì„ 3ì¤„ ì´ë‚´ë¡œ ìš”ì•½
2. **ë¶„ì„**: ë°ì´í„°ê°€ ì˜ë¯¸í•˜ëŠ” ê²ƒ í•´ì„ (ë¹„êµ, ì¶”ì´, ì´ìƒì¹˜ ë“±)
3. **ì¸ì‚¬ì´íŠ¸**: ë°œê²¬í•œ ì¤‘ìš”í•œ íŒ¨í„´ì´ë‚˜ íŠ¹ì´ì‚¬í•­
4. **ì˜ê²¬ ë° ì œì•ˆ**:
   - ì˜ì‚¬ê²°ì •ì— ë„ì›€ë˜ëŠ” êµ¬ì²´ì  ì¡°ì–¸
   - ì£¼ì˜í•  ì ì´ë‚˜ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­
   - ë‹¤ìŒ ì•¡ì…˜ ì•„ì´í…œ ì œì•ˆ

**ì¤‘ìš”**:
- í•œêµ­ì–´ë¡œ ë‹µë³€
- êµ¬ì²´ì ì¸ ìˆ«ìë¥¼ ì–¸ê¸‰í•˜ë©° ì„¤ëª…
- "~ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤", "~ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤" ê°™ì€ ì¶”ì¸¡ì„± í‘œí˜„ ëŒ€ì‹  ë°ì´í„° ê¸°ë°˜ ëª…í™•í•œ í‘œí˜„ ì‚¬ìš©
- ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ **ë¶„ì„ + ì˜ê²¬** ì œê³µ
- ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ì†”ì§íˆ ë§í•˜ê³  í•„ìš”í•œ ì¶”ê°€ ì •ë³´ ì œì•ˆ

ë‹µë³€:"""

        try:
            response = self.llm.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"âœ— Gemini ì˜¤ë¥˜: {e}")
            return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\n\nìˆ˜ì§‘ëœ ë°ì´í„°:\n{data_summary}"

    def format_response(self, response: UnifiedResponse) -> str:
        """ì‘ë‹µ í¬ë§·íŒ…"""
        parts = []

        # í—¤ë”
        parts.append(f"# ğŸ“Š ì§ˆë¬¸: {response.query}\n")
        parts.append(f"<small>ğŸ¯ ì²˜ë¦¬ ëª¨ë“œ: **{response.mode}** | {response.routing_info}</small>\n")
        parts.append("---\n")

        # Gemini ë¶„ì„
        parts.append("## ğŸ’¡ ë¶„ì„ ë° ì˜ê²¬\n")
        parts.append(response.gemini_analysis)
        parts.append("\n---\n")

        # ì›ë³¸ ë°ì´í„°
        parts.append("## ğŸ“‹ ìˆ˜ì§‘ëœ ë°ì´í„°\n")
        parts.append(f"```\n{response.data_summary}\n```")

        return "\n".join(parts)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    print("="*60)
    print("í†µí•© ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("="*60)

    from data_loader import DataLoader

    data_loader = DataLoader()
    data_loader.load_all_data()

    processor = UnifiedProcessor(data_loader)

    test_queries = [
        "ë§¤ì¶œ ìƒìœ„ 5ê°œ ê±°ë˜ì²˜ëŠ”?",
        "í•œêµ­ì¼€ë¯¸ì¹¼ìƒì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ê³  ê±°ë˜ ì „ëµ ì œì•ˆí•´ì¤˜",
        "ìµœê·¼ ì˜ì—…í™œë™ì€ ì–´ë–¤ê°€ìš”?",
    ]

    for query in test_queries:
        print(f"\n\n{'='*60}")
        print(f"í…ŒìŠ¤íŠ¸: {query}")
        print('='*60)

        response = processor.process(query)
        formatted = processor.format_response(response)
        print(formatted)
