"""
ë°ì´í„° ë¡œë” ë° ë¬¸ì„œ ë³€í™˜
"""
import pandas as pd
from typing import List, Dict
from config import (
    SALES_JOURNAL_PATH,
    SALES_DATA_PATH,
    CLIENT_DATA_PATH,
)
from utils import (
    load_csv_with_fallback,
    mask_sensitive_info,
    is_empty_value,
    extract_date_columns,
    parse_date_safe
)
from codebook_loader import get_codebook_loader


class Document:
    """RAG ë¬¸ì„œ í´ë˜ìŠ¤"""

    def __init__(self, text: str, metadata: Dict):
        self.text = text
        self.metadata = metadata

    def __repr__(self):
        return f"Document(metadata={self.metadata})"


class DataLoader:
    """ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë¬¸ì„œë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        self.codebook_loader = get_codebook_loader()
        self.documents = []
        self.raw_dataframes = {}  # {dataset_name: DataFrame}

    def load_all_data(self):
        """ëª¨ë“  ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë¬¸ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        print("\nğŸ“ ë°ì´í„° ë¡œë”© ì‹œì‘...")

        # 1. ê±°ë˜ì²˜ ë°ì´í„°
        self._load_and_convert(
            file_path=str(CLIENT_DATA_PATH),
            file_type="ê±°ë˜ì²˜ ë°ì´í„°",
            dataset_name="ê±°ë˜ì²˜"
        )

        # 2. ë§¤ì¶œ ë°ì´í„°
        self._load_and_convert(
            file_path=str(SALES_DATA_PATH),
            file_type="ë§¤ì¶œ ë°ì´í„°",
            dataset_name="ë§¤ì¶œ"
        )

        # 3. ì˜ì—…ì¼ì§€
        self._load_and_convert(
            file_path=str(SALES_JOURNAL_PATH),
            file_type="ì˜ì—…ì¼ì§€",
            dataset_name="ì˜ì—…ì¼ì§€"
        )

        print(f"\nâœ“ ì´ {len(self.documents)} ê°œì˜ ë¬¸ì„œ ìƒì„± ì™„ë£Œ")
        return self.documents

    def _load_and_convert(self, file_path: str, file_type: str, dataset_name: str):
        """
        CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë¬¸ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            file_path: CSV íŒŒì¼ ê²½ë¡œ
            file_type: íŒŒì¼ íƒ€ì… (ì½”ë“œë¶ì˜ "íŒŒì¼ êµ¬ë¶„"ê³¼ ì¼ì¹˜í•´ì•¼ í•¨)
            dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
        """
        print(f"\nğŸ“„ {dataset_name} ë¡œë”© ì¤‘...")

        # CSV ë¡œë“œ
        df = load_csv_with_fallback(file_path)
        if df is None:
            print(f"âœ— {dataset_name} ë¡œë“œ ì‹¤íŒ¨")
            return

        print(f"âœ“ {dataset_name} ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰, {len(df.columns)} ì—´")

        # ì›ë³¸ DataFrame ì €ì¥
        self.raw_dataframes[dataset_name] = df

        # ì»¬ëŸ¼ ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°
        column_mapping = self.codebook_loader.get_column_mapping(file_type)
        print(f"  ì½”ë“œ ë§¤í•‘: {len(column_mapping)} ê°œ")

        # ë‚ ì§œ ì»¬ëŸ¼ ì¶”ì¶œ
        date_columns = extract_date_columns(df)
        print(f"  ë‚ ì§œ ì»¬ëŸ¼: {date_columns}")

        # ê° í–‰ì„ ë¬¸ì„œë¡œ ë³€í™˜
        documents_created = 0
        for idx, row in df.iterrows():
            doc = self._row_to_document(
                row=row,
                row_id=idx,
                dataset_name=dataset_name,
                file_type=file_type,
                column_mapping=column_mapping,
                date_columns=date_columns
            )

            if doc:
                self.documents.append(doc)
                documents_created += 1

        print(f"  â†’ {documents_created} ê°œ ë¬¸ì„œ ìƒì„±")

    def _row_to_document(
            self,
            row: pd.Series,
            row_id: int,
            dataset_name: str,
            file_type: str,
            column_mapping: Dict[str, str],
            date_columns: List[str]
    ) -> Document:
        """
        DataFrameì˜ í•œ í–‰ì„ Documentë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            row: DataFrame í–‰
            row_id: í–‰ ID
            dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
            file_type: íŒŒì¼ íƒ€ì…
            column_mapping: ì»¬ëŸ¼ ì½”ë“œâ†’í•­ëª©ëª… ë§¤í•‘
            date_columns: ë‚ ì§œ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            Document ê°ì²´
        """
        # ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”
        metadata = {
            "dataset": dataset_name,
            "file_type": file_type,
            "row_id": int(row_id),
            "source": f"{dataset_name} (í–‰ {row_id + 1})"
        }

        # í…ìŠ¤íŠ¸ ë‚´ìš© êµ¬ì„±
        text_parts = []
        text_parts.append(f"[{dataset_name}]")

        # ê° ì»¬ëŸ¼ ì²˜ë¦¬
        for col_code in row.index:
            value = row[col_code]

            # ë¹ˆ ê°’ ìŠ¤í‚µ
            if is_empty_value(value):
                continue

            # ì»¬ëŸ¼ëª… ë²ˆì—­
            col_name = column_mapping.get(col_code, col_code)

            # ê°’ ì²˜ë¦¬
            value_str = str(value)

            # ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹
            value_str = mask_sensitive_info(value_str)

            # í…ìŠ¤íŠ¸ì— ì¶”ê°€
            text_parts.append(f"{col_name}: {value_str}")

            # íŠ¹ì • ì»¬ëŸ¼ì„ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
            # B-2 = ê±°ë˜ì²˜ì½”ë“œ
            if col_code == 'B-2':
                metadata['ê±°ë˜ì²˜ì½”ë“œ'] = value_str

            # B-1 = ê±°ë˜ì²˜ëª…
            if col_code == 'B-1':
                metadata['ê±°ë˜ì²˜ëª…'] = value_str

            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
            if col_code in date_columns:
                date_str = parse_date_safe(value)
                if date_str:
                    if 'ë‚ ì§œ' not in metadata:
                        metadata['ë‚ ì§œ'] = []
                    metadata['ë‚ ì§œ'].append(date_str)

        # ìµœì¢… í…ìŠ¤íŠ¸ ìƒì„±
        text = "\n".join(text_parts)

        # ë””ë²„ê¹…ìš©: ì›ë³¸ ì½”ë“œ/ê°’ë„ ì¶”ê°€
        text += f"\n\n[ì›ë³¸ ì½”ë“œ]"
        for col_code in row.index[:5]:  # ì²˜ìŒ 5ê°œë§Œ
            value = row[col_code]
            if not is_empty_value(value):
                text += f"\n{col_code}={value}"

        return Document(text=text, metadata=metadata)

    def get_dataframe(self, dataset_name: str) -> pd.DataFrame:
        """
        íŠ¹ì • ë°ì´í„°ì…‹ì˜ ì›ë³¸ DataFrameì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            dataset_name: ë°ì´í„°ì…‹ ì´ë¦„

        Returns:
            DataFrame ë˜ëŠ” None
        """
        return self.raw_dataframes.get(dataset_name)

    def filter_documents(self, dataset_filter: str = "ì „ì²´") -> List[Document]:
        """
        ë°ì´í„°ì…‹ í•„í„°ì— ë”°ë¼ ë¬¸ì„œë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.

        Args:
            dataset_filter: í•„í„° ("ì „ì²´", "ê±°ë˜ì²˜", "ë§¤ì¶œ", "ì˜ì—…ì¼ì§€")

        Returns:
            í•„í„°ë§ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if dataset_filter == "ì „ì²´":
            return self.documents

        return [doc for doc in self.documents if doc.metadata.get("dataset") == dataset_filter]


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    loader = DataLoader()
    loader.load_all_data()

    print("\n=== ë¬¸ì„œ ìƒ˜í”Œ ===")
    for i, doc in enumerate(loader.documents[:3]):
        print(f"\n--- ë¬¸ì„œ {i + 1} ---")
        print(f"ë©”íƒ€ë°ì´í„°: {doc.metadata}")
        print(f"í…ìŠ¤íŠ¸:\n{doc.text[:500]}...")
