"""
CALC ëª¨ë“œ: pandas ê¸°ë°˜ ì§‘ê³„/í†µê³„ ì—”ì§„
"""
import pandas as pd
import re
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass


@dataclass
class CalcResult:
    """ê³„ì‚° ê²°ê³¼"""
    answer: str
    result_df: Optional[pd.DataFrame]
    filter_conditions: List[str]
    sample_rows: List[Dict]
    sql_equivalent: str


class CalcEngine:
    """pandasë¥¼ ì‚¬ìš©í•œ ì§‘ê³„/í†µê³„ ê³„ì‚° ì—”ì§„"""

    def __init__(self, data_loader):
        """
        Args:
            data_loader: DataLoader ì¸ìŠ¤í„´ìŠ¤
        """
        self.data_loader = data_loader
        self.codebook_loader = data_loader.codebook_loader

    def calculate(self, query: str, dataset_filter: str = "ì „ì²´") -> CalcResult:
        """
        ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ pandas ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            dataset_filter: ë°ì´í„°ì…‹ í•„í„° (ì „ì²´/ê±°ë˜ì²˜/ë§¤ì¶œ/ì˜ì—…ì¼ì§€)

        Returns:
            CalcResult
        """
        print(f"\nğŸ“Š CALC ëª¨ë“œ: pandas ê³„ì‚° ìˆ˜í–‰")
        print(f"  ì§ˆë¬¸: {query}")
        print(f"  í•„í„°: {dataset_filter}")

        # ë°ì´í„°ì…‹ ì„ íƒ
        target_datasets = self._select_datasets(query, dataset_filter)
        print(f"  ëŒ€ìƒ ë°ì´í„°ì…‹: {target_datasets}")

        # ì§ˆë¬¸ ë¶„ì„
        analysis = self._analyze_query(query)
        print(f"  ë¶„ì„ ê²°ê³¼: {analysis}")

        # ê³„ì‚° ìˆ˜í–‰
        if len(target_datasets) == 1:
            result = self._calculate_single_dataset(
                query, target_datasets[0], analysis
            )
        else:
            result = self._calculate_multi_dataset(
                query, target_datasets, analysis
            )

        return result

    def _select_datasets(self, query: str, dataset_filter: str) -> List[str]:
        """ì§ˆë¬¸ê³¼ í•„í„°ì— ë”°ë¼ ëŒ€ìƒ ë°ì´í„°ì…‹ ì„ íƒ"""
        if dataset_filter != "ì „ì²´":
            return [dataset_filter]

        datasets = []

        # í‚¤ì›Œë“œë¡œ ë°ì´í„°ì…‹ ì¶”ë¡ 
        if any(word in query for word in ["ê±°ë˜ì²˜", "ê³ ê°", "ì—…ì²´", "ìƒí˜¸"]):
            datasets.append("ê±°ë˜ì²˜")

        if any(word in query for word in ["ë§¤ì¶œ", "íŒë§¤", "ì£¼ë¬¸", "ì œí’ˆ", "ë‹¨ê°€", "ê¸ˆì•¡"]):
            datasets.append("ë§¤ì¶œ")

        if any(word in query for word in ["ì˜ì—…ì¼ì§€", "ì¼ì§€", "ë°©ë¬¸", "ë©”ëª¨", "í™œë™"]):
            datasets.append("ì˜ì—…ì¼ì§€")

        # ê¸°ë³¸ê°’: ë§¤ì¶œ ë°ì´í„°
        if not datasets:
            datasets.append("ë§¤ì¶œ")

        return datasets

    def _analyze_query(self, query: str) -> Dict:
        """ì§ˆë¬¸ ë¶„ì„"""
        analysis = {
            "aggregation": None,  # sum, mean, count, max, min
            "groupby": None,      # ê±°ë˜ì²˜ë³„, ì œí’ˆë³„ ë“±
            "sort": None,         # ìƒìœ„, í•˜ìœ„
            "limit": None,        # Top N
            "time_range": None,   # ë‚ ì§œ ë²”ìœ„
            "filter_text": []     # í•„í„° ì¡°ê±´
        }

        # ì§‘ê³„ í•¨ìˆ˜
        if any(word in query for word in ["í•©ê³„", "ì´", "ì „ì²´"]):
            analysis["aggregation"] = "sum"
        elif any(word in query for word in ["í‰ê· "]):
            analysis["aggregation"] = "mean"
        elif any(word in query for word in ["ê°œìˆ˜", "ê±´ìˆ˜", "ëª‡", "ì¹´ìš´íŠ¸"]):
            analysis["aggregation"] = "count"
        elif any(word in query for word in ["ìµœëŒ€", "ìµœëŒ“ê°’", "ìµœê³ "]):
            analysis["aggregation"] = "max"
        elif any(word in query for word in ["ìµœì†Œ", "ìµœì†Ÿê°’", "ìµœì €"]):
            analysis["aggregation"] = "min"

        # ê·¸ë£¹í™”
        if "ê±°ë˜ì²˜ë³„" in query:
            analysis["groupby"] = "ê±°ë˜ì²˜"
        elif "ì œí’ˆë³„" in query or "í’ˆëª©ë³„" in query:
            analysis["groupby"] = "ì œí’ˆ"
        elif "ì›”ë³„" in query:
            analysis["groupby"] = "ì›”"
        elif "ë¶„ê¸°ë³„" in query:
            analysis["groupby"] = "ë¶„ê¸°"

        # ì •ë ¬ ë° ì œí•œ
        if "ìƒìœ„" in query or "top" in query.lower():
            analysis["sort"] = "desc"
            # Top N ì¶”ì¶œ
            match = re.search(r'(top|ìƒìœ„|í•˜ìœ„)\s*(\d+)', query.lower())
            if match:
                analysis["limit"] = int(match.group(2))
            else:
                analysis["limit"] = 5  # ê¸°ë³¸ê°’
        elif "í•˜ìœ„" in query:
            analysis["sort"] = "asc"
            match = re.search(r'í•˜ìœ„\s*(\d+)', query)
            if match:
                analysis["limit"] = int(match.group(2))
            else:
                analysis["limit"] = 5

        # ë‚ ì§œ ë²”ìœ„
        year_match = re.search(r'(\d{4})ë…„', query)
        month_match = re.search(r'(\d+)ì›”', query)
        if year_match:
            analysis["time_range"] = {"year": year_match.group(1)}
            if month_match:
                analysis["time_range"]["month"] = month_match.group(1)

        return analysis

    def _calculate_single_dataset(
        self, query: str, dataset_name: str, analysis: Dict
    ) -> CalcResult:
        """ë‹¨ì¼ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê³„ì‚°"""
        df = self.data_loader.get_dataframe(dataset_name)
        if df is None:
            return CalcResult(
                answer="ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                result_df=None,
                filter_conditions=[],
                sample_rows=[],
                sql_equivalent=""
            )

        filter_conditions = []
        sql_parts = [f"SELECT * FROM {dataset_name}"]

        # ë‚ ì§œ í•„í„° ì ìš©
        if analysis["time_range"]:
            time_filter = analysis["time_range"]
            # A-2 ì»¬ëŸ¼ (ë‚ ì§œ)ì´ ìˆëŠ”ì§€ í™•ì¸
            if 'A-2' in df.columns:
                original_len = len(df)
                if "year" in time_filter:
                    df = df[df['A-2'].astype(str).str.contains(time_filter["year"], na=False)]
                    filter_conditions.append(f"{time_filter['year']}ë…„ ë°ì´í„°")
                if "month" in time_filter:
                    month_str = time_filter["month"].zfill(2)
                    df = df[df['A-2'].astype(str).str.contains(f"-{month_str}", na=False)]
                    filter_conditions.append(f"{time_filter['month']}ì›” ë°ì´í„°")
                print(f"  ë‚ ì§œ í•„í„°: {original_len} â†’ {len(df)} í–‰")

        # ê·¸ë£¹í™” ë° ì§‘ê³„
        if analysis["groupby"]:
            result_df = self._perform_groupby(df, analysis, dataset_name)
        else:
            result_df = self._perform_simple_aggregation(df, analysis, dataset_name)

        # ì •ë ¬ ë° ì œí•œ
        if analysis["sort"] and result_df is not None:
            # ì²« ë²ˆì§¸ ìˆ«ì ì»¬ëŸ¼ìœ¼ë¡œ ì •ë ¬
            numeric_cols = result_df.select_dtypes(include=['number']).columns
            if len(numeric_cols) > 0:
                sort_col = numeric_cols[0]
                ascending = (analysis["sort"] == "asc")
                result_df = result_df.sort_values(by=sort_col, ascending=ascending)

                if analysis["limit"]:
                    result_df = result_df.head(analysis["limit"])
                    filter_conditions.append(f"{'ìƒìœ„' if not ascending else 'í•˜ìœ„'} {analysis['limit']}ê°œ")

        # ë‹µë³€ ìƒì„±
        answer = self._generate_calc_answer(query, result_df, filter_conditions, analysis)

        # ìƒ˜í”Œ í–‰ ì¶”ì¶œ
        sample_rows = self._extract_sample_rows(result_df, limit=5)

        return CalcResult(
            answer=answer,
            result_df=result_df,
            filter_conditions=filter_conditions,
            sample_rows=sample_rows,
            sql_equivalent=" ".join(sql_parts)
        )

    def _calculate_multi_dataset(
        self, query: str, dataset_names: List[str], analysis: Dict
    ) -> CalcResult:
        """ë‹¤ì¤‘ ë°ì´í„°ì…‹ ê³„ì‚° (ì¡°ì¸ í•„ìš”ì‹œ)"""
        # ê°„ë‹¨íˆ ì²« ë²ˆì§¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ì²˜ë¦¬
        return self._calculate_single_dataset(query, dataset_names[0], analysis)

    def _perform_groupby(self, df: pd.DataFrame, analysis: Dict, dataset_name: str) -> Optional[pd.DataFrame]:
        """ê·¸ë£¹í™” ë° ì§‘ê³„ ìˆ˜í–‰"""
        groupby_col = None

        if analysis["groupby"] == "ê±°ë˜ì²˜":
            # B-1 (ê±°ë˜ì²˜ëª…) ì»¬ëŸ¼ìœ¼ë¡œ ê·¸ë£¹í™”
            if 'B-1' in df.columns:
                groupby_col = 'B-1'
        elif analysis["groupby"] == "ì œí’ˆ":
            # C-2 (ì œí’ˆëª…) ì»¬ëŸ¼ìœ¼ë¡œ ê·¸ë£¹í™”
            if 'C-2' in df.columns:
                groupby_col = 'C-2'
        elif analysis["groupby"] == "ì›”":
            # A-2 (ë‚ ì§œ)ì—ì„œ ì›” ì¶”ì¶œ
            if 'A-2' in df.columns:
                df['ì›”'] = pd.to_datetime(df['A-2'], errors='coerce').dt.to_period('M').astype(str)
                groupby_col = 'ì›”'

        if not groupby_col or groupby_col not in df.columns:
            return None

        # ìˆ«ì ì»¬ëŸ¼ ì„ íƒ
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()

        if not numeric_cols:
            # ê±´ìˆ˜ë§Œ ì„¸ê¸°
            result_df = df.groupby(groupby_col).size().reset_index(name='ê±´ìˆ˜')
        else:
            # ì§‘ê³„ í•¨ìˆ˜ ì ìš©
            agg_func = analysis["aggregation"] or "sum"
            if agg_func == "sum":
                result_df = df.groupby(groupby_col)[numeric_cols].sum().reset_index()
            elif agg_func == "mean":
                result_df = df.groupby(groupby_col)[numeric_cols].mean().reset_index()
            elif agg_func == "count":
                result_df = df.groupby(groupby_col).size().reset_index(name='ê±´ìˆ˜')
            elif agg_func == "max":
                result_df = df.groupby(groupby_col)[numeric_cols].max().reset_index()
            elif agg_func == "min":
                result_df = df.groupby(groupby_col)[numeric_cols].min().reset_index()
            else:
                result_df = df.groupby(groupby_col)[numeric_cols].sum().reset_index()

        # ì½”ë“œë¶ìœ¼ë¡œ ì»¬ëŸ¼ëª… ë³€í™˜
        result_df = self._translate_columns(result_df, dataset_name)

        return result_df

    def _perform_simple_aggregation(self, df: pd.DataFrame, analysis: Dict, dataset_name: str) -> Optional[pd.DataFrame]:
        """ë‹¨ìˆœ ì§‘ê³„ (ê·¸ë£¹í™” ì—†ìŒ)"""
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()

        if not numeric_cols:
            return pd.DataFrame({"ê±´ìˆ˜": [len(df)]})

        agg_func = analysis["aggregation"] or "sum"

        result_dict = {}
        for col in numeric_cols[:5]:  # ìµœëŒ€ 5ê°œ ì»¬ëŸ¼
            if agg_func == "sum":
                result_dict[col] = [df[col].sum()]
            elif agg_func == "mean":
                result_dict[col] = [df[col].mean()]
            elif agg_func == "count":
                result_dict[col] = [df[col].count()]
            elif agg_func == "max":
                result_dict[col] = [df[col].max()]
            elif agg_func == "min":
                result_dict[col] = [df[col].min()]

        result_df = pd.DataFrame(result_dict)

        # ì½”ë“œë¶ìœ¼ë¡œ ì»¬ëŸ¼ëª… ë³€í™˜
        result_df = self._translate_columns(result_df, dataset_name)

        return result_df

    def _translate_columns(self, df: pd.DataFrame, dataset_name: str) -> pd.DataFrame:
        """ì½”ë“œë¶ì„ ì‚¬ìš©í•˜ì—¬ ì»¬ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë³€í™˜"""
        # ë§¤ì¶œ ë°ì´í„° â†’ sales data ë§¤í•‘
        dataset_map = {
            "ê±°ë˜ì²˜": "ê±°ë˜ì²˜ ë°ì´í„°",
            "ë§¤ì¶œ": "sales data",
            "ì˜ì—…ì¼ì§€": "ì˜ì—…ì¼ì§€"
        }

        file_type = dataset_map.get(dataset_name, dataset_name)
        column_mapping = self.codebook_loader.get_column_mapping(file_type)

        if not column_mapping:
            return df

        # ì»¬ëŸ¼ëª… ë³€í™˜
        rename_dict = {}
        for col in df.columns:
            if col in column_mapping:
                rename_dict[col] = column_mapping[col]

        if rename_dict:
            df = df.rename(columns=rename_dict)

        return df

    def _generate_calc_answer(
        self, query: str, result_df: Optional[pd.DataFrame],
        filter_conditions: List[str], analysis: Dict
    ) -> str:
        """ê³„ì‚° ê²°ê³¼ë¥¼ ìì—°ì–´ ë‹µë³€ìœ¼ë¡œ ìƒì„±"""
        if result_df is None or len(result_df) == 0:
            return "ê³„ì‚° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

        answer_parts = []

        # í•„í„° ì¡°ê±´
        if filter_conditions:
            answer_parts.append(f"**ì ìš©ëœ ì¡°ê±´**: {', '.join(filter_conditions)}")
            answer_parts.append("")

        # ê²°ê³¼ ìš”ì•½
        if len(result_df) == 1 and result_df.shape[1] <= 3:
            # ë‹¨ìˆœ ì§‘ê³„ ê²°ê³¼
            answer_parts.append("**ê³„ì‚° ê²°ê³¼**:")
            for col in result_df.columns:
                value = result_df[col].iloc[0]
                if isinstance(value, (int, float)):
                    answer_parts.append(f"- {col}: {value:,.0f}")
                else:
                    answer_parts.append(f"- {col}: {value}")
        else:
            # í…Œì´ë¸” í˜•íƒœ ê²°ê³¼
            answer_parts.append(f"**ê²°ê³¼**: ì´ {len(result_df)}ê°œ í•­ëª©")
            answer_parts.append("")
            answer_parts.append(self._dataframe_to_markdown(result_df.head(10)))

            if len(result_df) > 10:
                answer_parts.append(f"\n*(ìƒìœ„ 10ê°œë§Œ í‘œì‹œ, ì „ì²´ {len(result_df)}ê°œ)*")

        return "\n".join(answer_parts)

    def _dataframe_to_markdown(self, df: pd.DataFrame) -> str:
        """DataFrameì„ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜"""
        if df is None or len(df) == 0:
            return ""

        # ìˆ«ì í¬ë§·íŒ…
        df_display = df.copy()
        for col in df_display.columns:
            if df_display[col].dtype in ['int64', 'float64']:
                df_display[col] = df_display[col].apply(lambda x: f"{x:,.0f}" if pd.notna(x) else "")

        return df_display.to_markdown(index=False)

    def _extract_sample_rows(self, result_df: Optional[pd.DataFrame], limit: int = 5) -> List[Dict]:
        """ê²°ê³¼ì—ì„œ ìƒ˜í”Œ í–‰ ì¶”ì¶œ"""
        if result_df is None or len(result_df) == 0:
            return []

        sample_df = result_df.head(limit)
        return sample_df.to_dict('records')


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    from data_loader import DataLoader

    print("=" * 60)
    print("CALC ì—”ì§„ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    data_loader = DataLoader()
    calc_engine = CalcEngine(data_loader)

    test_queries = [
        "ë§¤ì¶œ ìƒìœ„ 5ê°œ ê±°ë˜ì²˜ëŠ”?",
        "ê±°ë˜ì²˜ë³„ ë§¤ì¶œ í•©ê³„ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
        "2024ë…„ 1ì›” ë§¤ì¶œ ì¶”ì´",
        "ì œí’ˆë³„ í‰ê·  ë‹¨ê°€ëŠ”?",
    ]

    for query in test_queries:
        print(f"\nì§ˆë¬¸: {query}")
        print("-" * 60)
        result = calc_engine.calculate(query, dataset_filter="ì „ì²´")
        print(result.answer)
        if result.sample_rows:
            print(f"\nìƒ˜í”Œ í–‰ ({len(result.sample_rows)}ê°œ):")
            for i, row in enumerate(result.sample_rows[:3], 1):
                print(f"  {i}. {row}")
