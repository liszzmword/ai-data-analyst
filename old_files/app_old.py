"""
Streamlit ê¸°ë°˜ RAG ì±—ë´‡ UI
"""
import streamlit as st
from pathlib import Path

from config import DEFAULT_TOP_K, MAX_TOP_K, DATASETS
from data_loader import DataLoader
from vector_store import VectorStore
from query_processor import QueryProcessor


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ“Š ë°ì´í„° ê¸°ë°˜ RAG ì±—ë´‡",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)


@st.cache_resource
def initialize_system():
    """ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤ (ìºì‹±)."""
    with st.spinner("ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
        # ë°ì´í„° ë¡œë“œ
        data_loader = DataLoader()
        documents = data_loader.load_all_data()

        # ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•
        vector_store = VectorStore()
        vector_store.build_index(documents)

        # ì§ˆì˜ ì²˜ë¦¬ê¸° ìƒì„±
        query_processor = QueryProcessor(vector_store, data_loader)

    return query_processor, data_loader, vector_store


def main():
    # ì œëª©
    st.title("ğŸ“Š ë°ì´í„° ê¸°ë°˜ RAG ì±—ë´‡")
    st.markdown("ê±°ë˜ì²˜, ë§¤ì¶œ, ì˜ì—…ì¼ì§€ ë°ì´í„°ë¥¼ ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”!")

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    try:
        query_processor, data_loader, vector_store = initialize_system()
    except Exception as e:
        st.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()

    # ì‚¬ì´ë“œë°” - í•„í„° ë° ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # ë°ì´í„°ì…‹ í•„í„°
        st.subheader("ğŸ“ ë°ì´í„°ì…‹ ì„ íƒ")
        dataset_options = ["ì „ì²´"] + list(DATASETS.keys())
        dataset_filter = st.selectbox(
            "ê²€ìƒ‰í•  ë°ì´í„°ì…‹",
            options=dataset_options,
            index=0
        )

        # Top-K ì„¤ì •
        st.subheader("ğŸ” ê²€ìƒ‰ ì„¤ì •")
        top_k = st.slider(
            "ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ (Top-K)",
            min_value=1,
            max_value=MAX_TOP_K,
            value=DEFAULT_TOP_K,
            step=1
        )

        # í†µê³„
        st.subheader("ğŸ“ˆ ë°ì´í„° í†µê³„")
        total_docs = len(vector_store.documents)
        st.metric("ì´ ë¬¸ì„œ ìˆ˜", f"{total_docs:,}")

        dataset_counts = {}
        for doc in vector_store.documents:
            dataset = doc.metadata.get('dataset', 'Unknown')
            dataset_counts[dataset] = dataset_counts.get(dataset, 0) + 1

        for dataset, count in dataset_counts.items():
            st.metric(f"{dataset}", f"{count:,}")

        # ìºì‹œ ì¬ìƒì„± ë²„íŠ¼
        st.subheader("ğŸ”§ ê´€ë¦¬")
        if st.button("ğŸ”„ ë²¡í„° ì¸ë±ìŠ¤ ì¬ìƒì„±"):
            with st.spinner("ì¬ìƒì„± ì¤‘..."):
                vector_store.clear_cache()
                st.cache_resource.clear()
                st.success("âœ… ì™„ë£Œ! í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
                st.rerun()

    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")

        # ì˜ˆì‹œ ì§ˆë¬¸
        with st.expander("ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸ ë³´ê¸°"):
            example_questions = [
                "í•œêµ­ì¼€ë¯¸ì¹¼ìƒì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
                "ì´ë†€ì˜ ê±°ë˜ì²˜ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
                "ìµœê·¼ ì˜ì—…ì¼ì§€ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”",
                "ë§¤ì¶œ ìƒìœ„ ê±°ë˜ì²˜ëŠ”?",
                "ê±°ë˜ì²˜ë³„ ë§¤ì¶œ í•©ê³„ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
                "PSì–‘ë©´ ì œí’ˆì„ êµ¬ë§¤í•œ ê±°ë˜ì²˜ëŠ”?",
                "ê±°ë˜ì²˜ ì¤‘ ëƒ‰ì¥ê³  ê´€ë ¨ ê±°ë˜ì²˜ëŠ”?",
                "ìµœê·¼ ë°©ë¬¸í•œ ê±°ë˜ì²˜ëŠ”?",
                "ì£¼ìš” ê±°ë˜ì²˜ ëª©ë¡ì„ ë³´ì—¬ì£¼ì„¸ìš”",
                "ë§¤ì¶œì•¡ì´ ë†’ì€ ì œí’ˆì€?"
            ]
            for i, q in enumerate(example_questions, 1):
                st.markdown(f"{i}. {q}")

        # ì§ˆë¬¸ ì…ë ¥
        query = st.text_input(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: í•œêµ­ì¼€ë¯¸ì¹¼ìƒì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            key="query_input"
        )

        # ê²€ìƒ‰ ë²„íŠ¼
        if st.button("ğŸ” ê²€ìƒ‰", type="primary") or query:
            if query.strip():
                with st.spinner("ğŸ¤” ë‹µë³€ ìƒì„± ì¤‘..."):
                    # ì§ˆì˜ ì²˜ë¦¬
                    result = query_processor.process_query(
                        query=query,
                        top_k=top_k,
                        dataset_filter=dataset_filter
                    )

                    # ë‹µë³€ í‘œì‹œ
                    st.markdown("### ğŸ“ ë‹µë³€")
                    st.markdown(result['answer'])

                    # í†µê³„ í‘œì‹œ (ìˆì„ ê²½ìš°)
                    if result['statistics'] is not None:
                        st.markdown("### ğŸ“Š í†µê³„")
                        st.dataframe(result['statistics'])

                    # ì¶œì²˜ í‘œì‹œ
                    st.markdown("---")
                    sources_text = query_processor.format_sources(result['sources'])
                    st.markdown(sources_text)

            else:
                st.warning("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    with col2:
        st.subheader("ğŸ“š ê·¼ê±° ë¬¸ì„œ")

        # ì„¸ì…˜ ìƒíƒœì— ê·¼ê±° ë¬¸ì„œ ì €ì¥
        if 'sources' not in st.session_state:
            st.session_state.sources = []

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
        if query and query.strip():
            try:
                result = query_processor.process_query(
                    query=query,
                    top_k=top_k,
                    dataset_filter=dataset_filter
                )
                st.session_state.sources = result['sources']
            except:
                pass

        # ê·¼ê±° ë¬¸ì„œ ì¹´ë“œ í‘œì‹œ
        if st.session_state.sources:
            for i, (doc, score) in enumerate(st.session_state.sources, 1):
                with st.expander(f"ğŸ“„ ë¬¸ì„œ {i} - {doc.metadata['source']} (ìœ ì‚¬ë„: {score:.4f})"):
                    # ë©”íƒ€ë°ì´í„°
                    st.markdown("**ë©”íƒ€ë°ì´í„°:**")
                    metadata = doc.metadata
                    if 'ê±°ë˜ì²˜ëª…' in metadata:
                        st.write(f"- ê±°ë˜ì²˜: {metadata['ê±°ë˜ì²˜ëª…']}")
                    if 'ê±°ë˜ì²˜ì½”ë“œ' in metadata:
                        st.write(f"- ê±°ë˜ì²˜ì½”ë“œ: {metadata['ê±°ë˜ì²˜ì½”ë“œ']}")
                    if 'ë‚ ì§œ' in metadata:
                        dates = metadata['ë‚ ì§œ']
                        if isinstance(dates, list) and dates:
                            st.write(f"- ë‚ ì§œ: {dates[0]}")

                    # ë¬¸ì„œ í…ìŠ¤íŠ¸
                    st.markdown("**ë‚´ìš©:**")
                    st.text_area(
                        "ë¬¸ì„œ ë‚´ìš©",
                        value=doc.text,
                        height=200,
                        key=f"doc_text_{i}",
                        label_visibility="collapsed"
                    )
        else:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

    # í‘¸í„°
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: gray; font-size: 12px;'>
        ğŸ“Š ë°ì´í„° ê¸°ë°˜ RAG ì±—ë´‡ | Powered by Sentence Transformers + FAISS + Google Gemini
        </div>
        """,
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
